{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R3gm/InsightSolver-Colab/blob/main/ImageColorizer_DISCO_Disentangled_Image_Colorization_via_Global_Anchors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DISCO\n",
        "\"Disentangled Image Colorization via Global Anchors\" presents the DISCO colorization model, with two components: (i) predicting global color anchors for the entire image, and (ii) generating per-pixel colors based on these anchors. The colorization process can be run using inference scripts."
      ],
      "metadata": {
        "id": "6Zc8c_kpOo4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Code Credits | Link |\n",
        "| ----------- | ---- |\n",
        "| ðŸŽ‰ Repository | [![GitHub Repository](https://img.shields.io/github/stars/MenghanXia/DisentangledColorization?style=social)](https://github.com/MenghanXia/DisentangledColorization) |\n",
        "| ðŸš€ Online inference | [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/menghanxia/disco) |\n",
        "| ðŸ”¥ Discover More Colab Notebooks | [![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-black?style=flat-square&logo=github)](https://github.com/R3gm/InsightSolver-Colab/) |"
      ],
      "metadata": {
        "id": "cYb8MQoZ1APm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA1VyFSQOAjd",
        "tags": []
      },
      "source": [
        "Config spaces in colab by `machinelearnear` original colab in\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/machinelearnear/open-hf-spaces-in-studiolab/blob/main/run_google_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmBjvPVHO1fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "b84cd137-cf9c-496a-f98a-e5549424f4d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mRunning on: \"Google Colab\"\u001b[0m\n",
            "\u001b[1mCloning repo... may take a few minutes... remember to set your Space to 'public'...\u001b[0m\n",
            "\u001b[1mInstalling requirements... may take a few minutes...\u001b[0m\n",
            "\u001b[1mUsing: \u001b[0m{'gpu_0': 'Tesla T4, 15360 MiB, 15098 MiB'}\n",
            "\u001b[1mDemo: `Disco`\n",
            "\u001b[0m\n",
            "\u001b[1mDownloading models... might take up to 10 minutes to finish...\u001b[0m\n",
            "\u001b[1mOnce finished, click the link below to open your application (in SM Studio Lab):\n",
            "\u001b[0m\n",
            "--2023-05-07 22:01:59--  https://huggingface.co/menghanxia/disco/resolve/main/disco-beta.pth.rar\n",
            "Resolving huggingface.co (huggingface.co)... 18.160.249.70, 18.160.249.31, 18.160.249.78, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.160.249.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/e9/e6/e9e63bf8a01864a93436a8bd5ae17cd37d40253953af0912d8399e1d56e6403d/b9d29e79c246813d4b07aa53e25d14a9f0d58f5a591a8f80a231d45514525db6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27disco-beta.pth.rar%3B+filename%3D%22disco-beta.pth.rar%22%3B&response-content-type=application%2Fvnd.rar&Expires=1683756120&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2U5L2U2L2U5ZTYzYmY4YTAxODY0YTkzNDM2YThiZDVhZTE3Y2QzN2Q0MDI1Mzk1M2FmMDkxMmQ4Mzk5ZTFkNTZlNjQwM2QvYjlkMjllNzljMjQ2ODEzZDRiMDdhYTUzZTI1ZDE0YTlmMGQ1OGY1YTU5MWE4ZjgwYTIzMWQ0NTUxNDUyNWRiNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODM3NTYxMjB9fX1dfQ__&Signature=ae0JOGVvKN99Rc3RB4Ygo7-IuHuj4TGSMvVVTQ0WZb4%7Ei3WVQezqc%7EQGyj3z-CQC1QqFTYey%7EFf0XSCFb6UQlsJKjqI3%7Eb%7EdsNi%7EwfUBK6%7EySp4zzoCJAlIroidVH4nLO8P9VhWNl2lBvztkVFaDCb3Dsed1Ifo4E0LRI2C-P9or06CP6S-4%7Edc4CRSykdJPjOfBAPPfIgeswtK-kzcvrH2mYFEqQd0bfk-XbKl0GfsH6KA6GJe1T04ow-RCOMrNjP4oZM7FqDGgieO3%7Eqw1BdFsDh24vcPwL8vbomnfyhFZSikhicsGfhra8nwhCK0AO0c3XVzfxfDqDoFXUX5e8Q__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-05-07 22:02:00--  https://cdn-lfs.huggingface.co/repos/e9/e6/e9e63bf8a01864a93436a8bd5ae17cd37d40253953af0912d8399e1d56e6403d/b9d29e79c246813d4b07aa53e25d14a9f0d58f5a591a8f80a231d45514525db6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27disco-beta.pth.rar%3B+filename%3D%22disco-beta.pth.rar%22%3B&response-content-type=application%2Fvnd.rar&Expires=1683756120&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2U5L2U2L2U5ZTYzYmY4YTAxODY0YTkzNDM2YThiZDVhZTE3Y2QzN2Q0MDI1Mzk1M2FmMDkxMmQ4Mzk5ZTFkNTZlNjQwM2QvYjlkMjllNzljMjQ2ODEzZDRiMDdhYTUzZTI1ZDE0YTlmMGQ1OGY1YTU5MWE4ZjgwYTIzMWQ0NTUxNDUyNWRiNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODM3NTYxMjB9fX1dfQ__&Signature=ae0JOGVvKN99Rc3RB4Ygo7-IuHuj4TGSMvVVTQ0WZb4%7Ei3WVQezqc%7EQGyj3z-CQC1QqFTYey%7EFf0XSCFb6UQlsJKjqI3%7Eb%7EdsNi%7EwfUBK6%7EySp4zzoCJAlIroidVH4nLO8P9VhWNl2lBvztkVFaDCb3Dsed1Ifo4E0LRI2C-P9or06CP6S-4%7Edc4CRSykdJPjOfBAPPfIgeswtK-kzcvrH2mYFEqQd0bfk-XbKl0GfsH6KA6GJe1T04ow-RCOMrNjP4oZM7FqDGgieO3%7Eqw1BdFsDh24vcPwL8vbomnfyhFZSikhicsGfhra8nwhCK0AO0c3XVzfxfDqDoFXUX5e8Q__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.94, 18.154.185.26, 18.154.185.64, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 499284894 (476M) [application/vnd.rar]\n",
            "Saving to: â€˜disco-beta.pth.rarâ€™\n",
            "\n",
            "disco-beta.pth.rar  100%[===================>] 476.15M  73.9MB/s    in 6.5s    \n",
            "\n",
            "2023-05-07 22:02:06 (72.8 MB/s) - â€˜disco-beta.pth.rarâ€™ saved [499284894/499284894]\n",
            "\n",
            "--2023-05-07 22:02:06--  https://huggingface.co/menghanxia/disco/resolve/main/01.jpg\n",
            "Resolving huggingface.co (huggingface.co)... 18.160.249.70, 18.160.249.31, 18.160.249.78, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.160.249.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 229205 (224K) [image/jpeg]\n",
            "Saving to: â€˜01.jpgâ€™\n",
            "\n",
            "01.jpg              100%[===================>] 223.83K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-05-07 22:02:07 (7.43 MB/s) - â€˜01.jpgâ€™ saved [229205/229205]\n",
            "\n",
            "--2023-05-07 22:02:07--  https://huggingface.co/menghanxia/disco/resolve/main/02.jpg\n",
            "Resolving huggingface.co (huggingface.co)... 18.160.249.70, 18.160.249.31, 18.160.249.78, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.160.249.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 100673 (98K) [image/jpeg]\n",
            "Saving to: â€˜02.jpgâ€™\n",
            "\n",
            "02.jpg              100%[===================>]  98.31K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-05-07 22:02:07 (5.97 MB/s) - â€˜02.jpgâ€™ saved [100673/100673]\n",
            "\n",
            "--2023-05-07 22:02:07--  https://huggingface.co/menghanxia/disco/resolve/main/03.jpg\n",
            "Resolving huggingface.co (huggingface.co)... 18.160.249.70, 18.160.249.31, 18.160.249.78, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.160.249.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130550 (127K) [image/jpeg]\n",
            "Saving to: â€˜03.jpgâ€™\n",
            "\n",
            "03.jpg              100%[===================>] 127.49K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-05-07 22:02:07 (5.02 MB/s) - â€˜03.jpgâ€™ saved [130550/130550]\n",
            "\n",
            "--2023-05-07 22:02:07--  https://huggingface.co/menghanxia/disco/resolve/main/04.jpg\n",
            "Resolving huggingface.co (huggingface.co)... 18.160.249.70, 18.160.249.31, 18.160.249.78, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.160.249.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113311 (111K) [image/jpeg]\n",
            "Saving to: â€˜04.jpgâ€™\n",
            "\n",
            "04.jpg              100%[===================>] 110.66K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-05-07 22:02:07 (5.11 MB/s) - â€˜04.jpgâ€™ saved [113311/113311]\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Checkbox, please remove them: {'default': False}\n",
            "  warnings.warn(\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://3bb4e54cfaf700b8ed.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            ">>>:automatic mode\n",
            ">>>:automatic mode\n",
            ">>>:automatic mode\n",
            ">>>:automatic mode\n",
            ">>>:automatic mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:automatic mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            ">>>:editable mode\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1999, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/disco/app_modified.py\", line 89, in <module>\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1916, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2002, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 43, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://3bb4e54cfaf700b8ed.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#@title DISCO configuration and run in gradio in one clic ðŸš€ Running on public URL\n",
        "# source: https://www.youtube.com/c/machinelearnear\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "try:\n",
        "    import gradio as gr\n",
        "except ImportError:\n",
        "    subprocess.run([\"pip\", \"install\", \"gradio\"])\n",
        "    import gradio as gr\n",
        "\n",
        "from os.path import exists as path_exists\n",
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "\n",
        "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
        "\n",
        "class RepoHandler:\n",
        "    def __init__(self, repo_url: str) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the RepoHandler class with the provided repository URL and requirements file.\n",
        "        Args:\n",
        "        - repo_url: URL of the git repository to clone.\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        self.is_google_colab = False\n",
        "        self.fix_for_gr, self.fix_for_st = None, None\n",
        "        self.app_file = \"app.py\"\n",
        "        if 'google.colab' in str(get_ipython()):\n",
        "            print(f'{bold}Running on: \"Google Colab\"{unbold}')\n",
        "            self.is_google_colab = True\n",
        "        else:\n",
        "            print(f'{bold}Running on: Local or \"SM Studio Lab\"{unbold}')\n",
        "        self.repo_url = repo_url\n",
        "        self.repo_name = self.repo_url.split('/')[-1]\n",
        "\n",
        "    def __str__(self):\n",
        "        if os.path.exists(self.repo_name):\n",
        "            return self.retrieve_readme(f'{self.repo_name}/README.md')\n",
        "        else:\n",
        "            print(f\"{bold}The repo '{self.repo_name}' has not been cloned yet.{unbold}\")\n",
        "            return None\n",
        "\n",
        "    def retrieve_readme(self, filename) -> Dict:\n",
        "        readme = {}\n",
        "        if path_exists(filename):\n",
        "            with open(filename) as f:\n",
        "                for line in f:\n",
        "                    if line.find('http') > 0: continue\n",
        "                    if not line.find(':') > 0 or 'Check' in line: continue\n",
        "                    (k,v) = line.split(':')\n",
        "                    readme[(k)] = v.strip().replace('\\n','')\n",
        "        else:\n",
        "            print(f\"{bold}No 'readme.md' file{unbold}\")\n",
        "\n",
        "        return readme\n",
        "\n",
        "    def clone_repo(self, overwrite=False) -> None:\n",
        "        \"\"\"\n",
        "        Clone the git repository specified in the repo_url attribute.\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        # Check if repository has already been cloned locally\n",
        "        if overwrite and os.path.exists(self.repo_name):\n",
        "            try:\n",
        "                shutil.rmtree(self.repo_name)\n",
        "            except OSError as e:\n",
        "                print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "        if os.path.exists(self.repo_name):\n",
        "            print(f\"{bold}Repository '{self.repo_name}' has already been cloned.{unbold}\")\n",
        "        else:\n",
        "            print(f\"{bold}Cloning repo... may take a few minutes... remember to set your Space to 'public'...{unbold}\")\n",
        "            subprocess.run([\"apt-get\", \"install\", \"git-lfs\"])\n",
        "            subprocess.run([\"git\", \"lfs\", \"install\", \"--system\", \"--skip-repo\"])\n",
        "            subprocess.run([\"git\", \"clone\", \"--recurse-submodules\", self.repo_url])\n",
        "\n",
        "    def install_requirements(self, requirements_file: str = None, install_xformers: bool = False) -> None:\n",
        "        \"\"\"\n",
        "        Install the requirements specified in the requirements_file attribute.\n",
        "\n",
        "        Args:\n",
        "        - requirements_file: Name of the file containing the requirements to install. This file must be\n",
        "        located in the root directory of the repository. Defaults to \"requirements.txt\".\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        if not requirements_file: requirements_file = f\"{self.repo_name}/requirements.txt\"\n",
        "\n",
        "        # install requirements\n",
        "        print(f\"{bold}Installing requirements... may take a few minutes...{unbold}\")\n",
        "        subprocess.run([\"pip\", \"install\", \"-r\", requirements_file])\n",
        "        if install_xformers: self.install_xformers()\n",
        "\n",
        "    def run_web_demo(self, aws_domain=None, aws_region=None) -> None:\n",
        "        \"\"\"\n",
        "        Launch the Gradio or Streamlit web demo for the cloned repository.\n",
        "        Works with Google Colab or SageMaker Studio Lab.\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        import torch\n",
        "        if torch.cuda.is_available(): print(f\"{bold}Using: {unbold}{self.get_gpu_memory_map()}\")\n",
        "        else: print(f\"{bold}Not using the GPU{unbold}\")\n",
        "\n",
        "        readme = self.__str__()\n",
        "        self.app_file = readme[\"app_file\"]\n",
        "        print(f\"{bold}Demo: `{readme['title']}`{newline}{unbold}\")\n",
        "        print(f\"{bold}Downloading models... might take up to 10 minutes to finish...{unbold}\")\n",
        "        print(f\"{bold}Once finished, click the link below to open your application (in SM Studio Lab):{newline}{unbold}\")\n",
        "        if all([aws_domain, aws_region]):\n",
        "              print(f'{bold}https://{aws_domain}.studio.{aws_region}.sagemaker.aws/studiolab/default/jupyter/proxy/6006/{unbold}')\n",
        "\n",
        "        self.unset_environment_variables()\n",
        "\n",
        "        if readme[\"sdk\"] == 'gradio':\n",
        "            gr.close_all()\n",
        "            if not self.is_google_colab:\n",
        "                !export GRADIO_SERVER_PORT=6006 && cd $self.repo_name && python $self.app_file\n",
        "                # os.system(f'export GRADIO_SERVER_PORT=6006 && cd {self.repo_name} && python {readme[\"app_file\"]}')\n",
        "            else:\n",
        "                new_filename = self.replace_gradio_launcher(f'{self.repo_name}/{readme[\"app_file\"]}')\n",
        "                !cd $self.repo_name && python $new_filename\n",
        "                # os.system(f'cd {self.repo_name} && python {readme[\"app_file\"]}')\n",
        "        elif readme[\"title\"] == 'streamlit':\n",
        "            if not self.is_google_colab:\n",
        "                !cd $self.repo_name && streamlit run $self.app_file --server.port 6006\n",
        "                # os.system(f'cd {self.repo_name} && streamlit run {readme[\"app_file\"]} --server.port 6006')\n",
        "            else:\n",
        "                !cd $self.repo_name && streamlit run $self.app_file\n",
        "                # os.system(f'cd {self.repo_name} && streamlit run {readme[\"app_file\"]}')\n",
        "        else:\n",
        "            print('This notebook will not work with static apps hosted on \"Spaces\"')\n",
        "\n",
        "    def get_gpu_memory_map(self) -> Dict[str, int]:\n",
        "        \"\"\"Get the current gpu usage.\n",
        "        Return:\n",
        "            A dictionary in which the keys are device ids as integers and\n",
        "            values are memory usage as integers in MB.\n",
        "        \"\"\"\n",
        "        result = subprocess.run(\n",
        "            [\"nvidia-smi\", \"--query-gpu=name,memory.total,memory.free\", \"--format=csv,noheader\",],\n",
        "            encoding=\"utf-8\",\n",
        "            # capture_output=True,          # valid for python version >=3.7\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,  # for backward compatibility with python version 3.6\n",
        "            check=True,\n",
        "        )\n",
        "        # Convert lines into a dictionary, return f\"{}\"\n",
        "        gpu_memory = [x for x in result.stdout.strip().split(os.linesep)]\n",
        "        gpu_memory_map = {f\"gpu_{index}\": memory for index, memory in enumerate(gpu_memory)}\n",
        "\n",
        "        return gpu_memory_map\n",
        "\n",
        "    def replace_gradio_launcher(self, old_filename) -> str:\n",
        "        # Read the contents of the file\n",
        "        with open(old_filename, \"r\") as f:\n",
        "            contents = f.read()\n",
        "        # Define the regular expression pattern\n",
        "        pattern = r\"\\.launch\\((.*?)\\)\"\n",
        "        # Use the sub method to replace the text\n",
        "        contents = re.sub(pattern, \".launch(share=True)\", contents)\n",
        "        # Write the modified contents back to the file\n",
        "        new_filename = Path(old_filename).parent / f\"{Path(old_filename).stem}_modified.py\"\n",
        "        with open(new_filename, \"w\") as f:\n",
        "            f.write(contents)\n",
        "\n",
        "        return new_filename.name\n",
        "\n",
        "    def unset_environment_variables(self) -> None:\n",
        "        os.unsetenv(\"SHARED_UI\")\n",
        "        os.environ.pop(\"SHARED_UI\", None)\n",
        "\n",
        "        os.unsetenv(\"IS_SHARED\")\n",
        "        os.environ.pop(\"IS_SHARED\", None)\n",
        "\n",
        "    def install_xformers(self) -> None:\n",
        "        from subprocess import getoutput\n",
        "        from IPython.display import HTML\n",
        "        from IPython.display import clear_output\n",
        "        import time\n",
        "\n",
        "        subprocess.run([\"pip\", \"install\", \"-U\", \"--pre\", \"triton\"])\n",
        "\n",
        "        s = getoutput('nvidia-smi')\n",
        "        if 'T4' in s: gpu = 'T4'\n",
        "        elif 'P100' in s: gpu = 'P100'\n",
        "        elif 'V100' in s: gpu = 'V100'\n",
        "        elif 'A100' in s: gpu = 'A100'\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "            print(f'{bold} Seems that your GPU is not supported at the moment.{unbold}')\n",
        "            time.sleep(5)\n",
        "\n",
        "        if (gpu=='T4'):\n",
        "            precompiled_wheels = \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\"\n",
        "        elif (gpu=='P100'):\n",
        "            precompiled_wheels = \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\"\n",
        "        elif (gpu=='V100'):\n",
        "            precompiled_wheels = \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\"\n",
        "        elif (gpu=='A100'):\n",
        "            precompiled_wheels = \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\"\n",
        "\n",
        "        subprocess.run([\"pip\", \"install\", \"-q\", precompiled_wheels])\n",
        "\n",
        "app = RepoHandler(\n",
        "    repo_url='https://huggingface.co/spaces/menghanxia/disco'\n",
        ")\n",
        "app.clone_repo(overwrite=True)\n",
        "app.install_requirements()\n",
        "app.run_web_demo()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}